
<center><font size = 6>PointCloud概述</font></center>

## 1.三维数据的表现形式
```ad-note
![](https://drailife.oss-cn-beijing.aliyuncs.com/img/202209170032192.png)
1.**Point Cloud（点云）**:由$N$$个$D$维的点组成，当这个 $D = 3$ 的时候一般代表着$( x , y , z )$ 的坐标，当然也可以包括温度、强度、颜色特征( A point cloud is represented as a set of 3D points $\{Pi| i = 1, ..., n\}$, where each point Pi is a vector of its $(x, y, z)$ coordinate plus extra feature channels such as color, normal etc)
2. Mesh: 由三角面片和正方形面片组成
3. Volumetric(体素): 由三维栅格将物体用0和1表征
4. Muti-view images(多视角): 多角度的RGB图像或者RGB-D图像

^1769fa
```


## 2. 点云的特性
```ad-note
title:1.$Unordered$(无序性)
&emsp:&emsp;点的排列顺序不影响物体在三维空间中的形状特征，相同的点云可以由两个完全不同的矩阵表示$Figure 1$在点的数据相同的情况下左，右边排序方式都代表同一个物体

![](https://drailife.oss-cn-beijing.aliyuncs.com/img/202209170032857.png)
<center><font size=2>Figure 1</font></center>
&emsp;&emsp;我们希望对上面左右两个输入都能够提取到相同的特征，因此我们在设计的网络需要具有**对称性**，eg. Sum 和 Max函数。如$Figure2$所示，无论左边输入排序如何，都会得到右边的结果，利用Sum方法也会得到同样的结果

![](https://drailife.oss-cn-beijing.aliyuncs.com/img/202209170033889.png)<center><font size=2>Figure 2</font></center>

&emsp;上面的简单网络虽然能够满足提取到相同的特征，但是显而易见，我们只保留了其中最大值，丢失了许多其他的信息。
&emsp;&emsp;我们可以考虑先将每一个点映射到高维的空间中（如：1024维），此时再进行特征提取，便可以减少信息的损失量
^100
```
```ad-note
title:3.Interaction among points(点之间相互联系)
&emsp;&emsp;这些点来自一个有距离度量的空间。这意味着点不是孤立的，相邻的点形成一个有意义的子集。因此，该模型需要能够从附近的点捕捉局部结构，以及局部结构之间的组合相互作用
```
```ad-note
title:Invariance under transformations(转换不变性)
&emsp;&emsp;点云作为一个几何对象，学习到的点集表示对于某些变换应该是不变的。例如，同时旋转和平移点不应该修改全局点云类别或点的分割
&emsp;&emsp;对于一个点云对象，无论我们是将它旋转90°，或者说向右平移一定的距离，在输入到我们的网络模型中去，我们都希望得到相同的结果
```
##  3.解决方案
```ad-note
title:Solution
1. $Volumetric CNNs$:&emsp;are the pioneers applying 3D convolutional neural net-works on voxelized shapes. However, volumetric representation is con-strained by its resolution due to data sparsity and computation cost of 3D convolution.
2.  $Multiview CNNs$:&emsp;have tried to render 3D point cloud or shapes into 2D images and then apply 2D conv nets to classify them
```

